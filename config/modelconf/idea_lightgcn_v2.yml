optimizer:
  name: adam
  lr: 1.0e-3 # not 1e-3
  weight_decay: 0

train:
  epoch: 500
  batch_size: 4096
  save_model: false
  loss: pairwise # bpr
  log_loss: false # whether to log loss
  test_step: 3 # evaluate per {test_step} epochs
  patience: 5
  reproducible: true
  seed: 2023
  #pretrain_path: ./checkpoint/xxxx.pth

test:
  metrics: [recall, ndcg] # choose in {ndcg, recall, precision, mrr}
  k: [10, 20, 40] # top-k
  batch_size: 1024 # How many users per batch during validation

data:
  type: social # choose in {general_cf, multi_behavior, sequential, social}
  name: yelp


model:
  name: idea_lightgcn_v2 # case-insensitive
  layer_num: 3
  reg_weight: 1.0e-6
  embedding_size: 64
  
  # --- Options --- #
  # You can toggle between true and false, or exclude an option by commenting it out.
  self_gating_unit: true
  pagerank: false
  combine_gcn: false
  alpha: 0.9
  cl_weight: 1.0e-5
  sigma: 20 # std for exponential RBF kernel
  # socially_aware_normalization: true
  not_normalize: false

tune:
  enable: true # Whether to enable grid search to search for optimal hyperparameters
  hyperparameters: [layer_num, reg_weight, cl_weight, alpha] # The name of the hyperparameter
  layer_num: [2, 3] # Use a list to store the search range
  reg_weight: [1.0e-6, 1.0e-7, 1.0e-8]
  cl_weight: [1.0e-5, 1.0e-6, 1.0e-7]
  alpha: [0.7, 0.8, 0.9]
